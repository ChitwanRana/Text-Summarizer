{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"Game of Thrones is an American fantasy drama television series created by David Benioff and D. B. Weiss for HBO. It is an adaptation of A Song of Ice and Fire, a series of fantasy novels by George R. R. Martin, the first of which is A Game of Thrones. The show premiered on HBO in the United States on April 17, 2011, and concluded on May 19, 2019, with 73 episodes broadcast over eight seasons.\n",
    "\n",
    "Set on the fictional continents of Westeros and Essos, Game of Thrones has a large ensemble cast and follows several story arcs throughout the course of the show. The first major arc concerns the Iron Throne of the Seven Kingdoms of Westeros through a web of political conflicts among the noble families either vying to claim the throne or fighting for independence from whoever sits on it.\n",
    "\n",
    " The second major arc focuses on the last descendant of the realm's deposed ruling dynasty, who has been exiled to Essos and is plotting to return and reclaim the throne. The third follows the Night's Watch, a military order defending the realm against threats from beyond the Seven Kingdoms' northern border.\"\"\"\n",
    "\n",
    "\n",
    "def summarizer(rawdocs): \n",
    "    stopwords = list(STOP_WORDS)\n",
    "    # print(stopwords)\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(rawdocs)\n",
    "    \n",
    "    tokens = [token.text for token in doc]\n",
    "    # print(tokens)\n",
    "\n",
    "    # It picks up each word from doc, converts it into lower case and checks if it is in stopwords or punctuations.\n",
    "    word_freq = {}\n",
    "    # Each word will be added into the dictionary and assigned a value.\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in stopwords and word.text.lower() not in punctuation:\n",
    "            # If not, convert word into text and check if word is in word_freq's dictionary. \n",
    "            # If not, then assign that word 1, and if repeated again, then increase its value.\n",
    "            if word.text not in word_freq.keys():\n",
    "                word_freq[word.text] = 1\n",
    "            else:\n",
    "                word_freq[word.text] += 1\n",
    "\n",
    "    # print(word_freq)\n",
    "    max_freq = max(word_freq.values())\n",
    "    # print(max_freq)\n",
    "\n",
    "    # Normalized frequency = frequency of each word / max frequency.\n",
    "    for word in word_freq.keys():\n",
    "        word_freq[word] = word_freq[word] / max_freq\n",
    "    # print(word_freq)\n",
    "\n",
    "    # Sentence tokenize  \n",
    "    sent_tokens = [sent for sent in doc.sents]\n",
    "    # print(sent_tokens)\n",
    "\n",
    "    # Make dictionary for sentence in a similar manner\n",
    "    sent_score = {}\n",
    "    for sent in sent_tokens:  # Picking each sentence from tokens.\n",
    "        for word in sent:     # Picking each word from the tokenized sentence.\n",
    "            if word.text in word_freq.keys():  # Check if the word exists in word_freq dictionary.\n",
    "                if sent not in sent_score.keys():  # If the sentence doesn't exist in sent_score, add it.\n",
    "                    sent_score[sent] = word_freq[word.text]  # Assign value.\n",
    "                else:\n",
    "                    sent_score[sent] += word_freq[word.text]  # Add the normalized frequency.\n",
    "\n",
    "    # It calculates the total frequency of each sentence.\n",
    "    # print(sent_score)  # Total frequency of each sentence.\n",
    "\n",
    "    select_len = int(len(sent_tokens) * 0.3)  # 30% length of sent tokens.\n",
    "    # print(select_len)\n",
    "\n",
    "    # Select sentences with the highest frequency from sent_score.\n",
    "    summary = nlargest(select_len, sent_score, key=sent_score.get)\n",
    "    final_summary = [word.text for word in summary]  # Make a list using word.text and join by space.\n",
    "    summary = ' '.join(final_summary)\n",
    "    \n",
    "    # print(\"Original Text is: \")\n",
    "    # print(rawdocs)\n",
    "    # print(\"_________________________________________________________________________________________________\")\n",
    "    # print(\"Summarized Text is:\")\n",
    "    # print(summary)\n",
    "    # print(\"_________________________________________________________________________________________________\")\n",
    "\n",
    "    # print(\"Length Of Original Text:\", len(rawdocs.split(' ')))\n",
    "    # print(\"Length Of Summarized Text:\", len(summary.split(' ')))\n",
    "\n",
    "    return summary,doc,len(rawdocs.split(' ')),len(summary.split(' '))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
